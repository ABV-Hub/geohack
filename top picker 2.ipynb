{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lasio\n",
    "import glob\n",
    "import seaborn\n",
    "from __future__ import division\n",
    "import cProfile\n",
    "\n",
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l=lasio.read(r'D:\\geohack\\LAS\\5002320004.las') #reads the well log .las file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPT\t[F]\t\t1  DEPTH\n",
      "SP\t[MV]\t\t2\n",
      "LL8\t[OHMM]\t\t3\n",
      "ILD\t[OHMM]\t\t4\n",
      "CILD\t[MMHO]\t\t5\n",
      "DT\t[US/F]\t\t6\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "for curve in l.curves:\n",
    "    print(\"%s\\t[%s]\\t%s\\t%s\" % (curve.mnemonic, curve.unit, curve.value, curve.descr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>sn</th>\n",
       "      <th>sp</th>\n",
       "      <th>ild</th>\n",
       "      <th>cild</th>\n",
       "      <th>dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1244.0</td>\n",
       "      <td>None</td>\n",
       "      <td>-48.1566</td>\n",
       "      <td>17.1605</td>\n",
       "      <td>5.3554</td>\n",
       "      <td>133.2647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1244.5</td>\n",
       "      <td>None</td>\n",
       "      <td>-47.7312</td>\n",
       "      <td>17.0697</td>\n",
       "      <td>27.6594</td>\n",
       "      <td>127.2877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1245.0</td>\n",
       "      <td>None</td>\n",
       "      <td>-47.5771</td>\n",
       "      <td>15.7413</td>\n",
       "      <td>66.3134</td>\n",
       "      <td>117.3461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1245.5</td>\n",
       "      <td>None</td>\n",
       "      <td>-47.3122</td>\n",
       "      <td>13.1640</td>\n",
       "      <td>73.5441</td>\n",
       "      <td>114.8084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1246.0</td>\n",
       "      <td>None</td>\n",
       "      <td>-46.1779</td>\n",
       "      <td>11.2701</td>\n",
       "      <td>89.5565</td>\n",
       "      <td>114.4879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    depth    sn       sp      ild     cild        dt\n",
       "0  1244.0  None -48.1566  17.1605   5.3554  133.2647\n",
       "1  1244.5  None -47.7312  17.0697  27.6594  127.2877\n",
       "2  1245.0  None -47.5771  15.7413  66.3134  117.3461\n",
       "3  1245.5  None -47.3122  13.1640  73.5441  114.8084\n",
       "4  1246.0  None -46.1779  11.2701  89.5565  114.4879"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr = pd.Series(l['ILD']).fillna(value=0)\n",
    "depth = pd.Series(l['DEPT']).fillna(value=0)\n",
    "df = pd.DataFrame()\n",
    "df['depth'] = l['DEPT']\n",
    "df['sn'] = l['SN']\n",
    "df['sp'] = l['SP']\n",
    "df['ild'] = l['ILD']\n",
    "df['cild'] = l['CILD']\n",
    "df['dt'] = l['DT']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use scipy logsumexp().\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from scipy.special import gammaln, multigammaln\n",
    "from scipy.misc import comb\n",
    "from decorator import decorator\n",
    "\n",
    "# This makes the code compatible with Python 3\n",
    "# without causing performance hits on Python 2\n",
    "try:\n",
    "    xrange\n",
    "except NameError:\n",
    "    xrange = range\n",
    "\n",
    "\n",
    "try:\n",
    "    from sselogsumexp import logsumexp\n",
    "except ImportError:\n",
    "    from scipy.special import logsumexp\n",
    "    print(\"Use scipy logsumexp().\")\n",
    "else:\n",
    "    print(\"Use SSE accelerated logsumexp().\")\n",
    "\n",
    "\n",
    "def _dynamic_programming(f, *args, **kwargs):\n",
    "    if f.data is None:\n",
    "        f.data = args[0]\n",
    "\n",
    "    if not np.array_equal(f.data, args[0]):\n",
    "        f.cache = {}\n",
    "        f.data = args[0]\n",
    "\n",
    "    try:\n",
    "        f.cache[args[1:3]]\n",
    "    except KeyError:\n",
    "        f.cache[args[1:3]] = f(*args, **kwargs)\n",
    "    return f.cache[args[1:3]]\n",
    "\n",
    "def dynamic_programming(f):\n",
    "    f.cache = {}\n",
    "    f.data = None\n",
    "    return decorator(_dynamic_programming, f)\n",
    "\n",
    "\n",
    "def offline_changepoint_detection(data, prior_func,\n",
    "                                  observation_log_likelihood_function,\n",
    "                                  truncate=-np.inf):\n",
    "    \"\"\"Compute the likelihood of changepoints on data.\n",
    "    Keyword arguments:\n",
    "    data                                -- the time series data\n",
    "    prior_func                          -- a function given the likelihood of a changepoint given the distance to the last one\n",
    "    observation_log_likelihood_function -- a function giving the log likelihood\n",
    "                                           of a data part\n",
    "    truncate                            -- the cutoff probability 10^truncate to stop computation for that changepoint log likelihood\n",
    "    P                                   -- the likelihoods if pre-computed\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(data)\n",
    "    Q = np.zeros((n,))\n",
    "    g = np.zeros((n,))\n",
    "    G = np.zeros((n,))\n",
    "    P = np.ones((n, n)) * -np.inf\n",
    "\n",
    "    # save everything in log representation\n",
    "    for t in range(n):\n",
    "        g[t] = np.log(prior_func(t))\n",
    "        if t == 0:\n",
    "            G[t] = g[t]\n",
    "        else:\n",
    "            G[t] = np.logaddexp(G[t-1], g[t])\n",
    "\n",
    "    P[n-1, n-1] = observation_log_likelihood_function(data, n-1, n)\n",
    "    Q[n-1] = P[n-1, n-1]\n",
    "\n",
    "    for t in reversed(range(n-1)):\n",
    "        P_next_cp = -np.inf  # == log(0)\n",
    "        for s in range(t, n-1):\n",
    "            P[t, s] = observation_log_likelihood_function(data, t, s+1)\n",
    "\n",
    "            # compute recursion\n",
    "            summand = P[t, s] + Q[s + 1] + g[s + 1 - t]\n",
    "            P_next_cp = np.logaddexp(P_next_cp, summand)\n",
    "\n",
    "            # truncate sum to become approx. linear in time (see\n",
    "            # Fearnhead, 2006, eq. (3))\n",
    "            if summand - P_next_cp < truncate:\n",
    "                break\n",
    "\n",
    "        P[t, n-1] = observation_log_likelihood_function(data, t, n)\n",
    "\n",
    "        # (1 - G) is numerical stable until G becomes numerically 1\n",
    "        if G[n-1-t] < -1e-15:  # exp(-1e-15) = .99999...\n",
    "            antiG = np.log(1 - np.exp(G[n-1-t]))\n",
    "        else:\n",
    "            # (1 - G) is approx. -log(G) for G close to 1\n",
    "            antiG = np.log(-G[n-1-t])\n",
    "\n",
    "        Q[t] = np.logaddexp(P_next_cp, P[t, n-1] + antiG)\n",
    "\n",
    "    Pcp = np.ones((n-1, n-1)) * -np.inf\n",
    "    for t in range(n-1):\n",
    "        Pcp[0, t] = P[0, t] + Q[t + 1] + g[t] - Q[0]\n",
    "        if np.isnan(Pcp[0, t]):\n",
    "            Pcp[0, t] = -np.inf\n",
    "    for j in range(1, n-1):\n",
    "        for t in range(j, n-1):\n",
    "            tmp_cond = Pcp[j-1, j-1:t] + P[j:t+1, t] + Q[t + 1] + g[0:t-j+1] - Q[j:t+1]\n",
    "            Pcp[j, t] = logsumexp(tmp_cond.astype(np.float32))\n",
    "            if np.isnan(Pcp[j, t]):\n",
    "                Pcp[j, t] = -np.inf\n",
    "\n",
    "    return Q, P, Pcp\n",
    "\n",
    "@dynamic_programming\n",
    "def gaussian_obs_log_likelihood(data, t, s):\n",
    "    s += 1\n",
    "    n = s - t\n",
    "    mean = data[t:s].sum(0) / n\n",
    "\n",
    "    muT = (n * mean) / (1 + n)\n",
    "    nuT = 1 + n\n",
    "    alphaT = 1 + n / 2\n",
    "    betaT = 1 + 0.5 * ((data[t:s] - mean) ** 2).sum(0) + ((n)/(1 + n)) * (mean**2 / 2)\n",
    "    scale = (betaT*(nuT + 1))/(alphaT * nuT)\n",
    "\n",
    "    # splitting the PDF of the student distribution up is /much/ faster.\n",
    "    # (~ factor 20) using sum over for loop is even more worthwhile\n",
    "    prob = np.sum(np.log(1 + (data[t:s] - muT)**2/(nuT * scale)))\n",
    "    lgA = gammaln((nuT + 1) / 2) - np.log(np.sqrt(np.pi * nuT * scale)) - gammaln(nuT/2)\n",
    "\n",
    "    return np.sum(n * lgA - (nuT + 1)/2 * prob)\n",
    "\n",
    "def ifm_obs_log_likelihood(data, t, s):\n",
    "    '''Independent Features model from xuan et al'''\n",
    "    s += 1\n",
    "    n = s - t\n",
    "    x = data[t:s]\n",
    "    if len(x.shape)==2:\n",
    "        d = x.shape[1]\n",
    "    else:\n",
    "        d = 1\n",
    "        x = np.atleast_2d(x).T\n",
    "\n",
    "    N0 = d          # weakest prior we can use to retain proper prior\n",
    "    V0 = np.var(x)\n",
    "    Vn = V0 + (x**2).sum(0)\n",
    "\n",
    "    # sum over dimension and return (section 3.1 from Xuan paper):\n",
    "    return d*( -(n/2)*np.log(np.pi) + (N0/2)*np.log(V0) - \\\n",
    "        gammaln(N0/2) + gammaln((N0+n)/2) ) - \\\n",
    "        ( ((N0+n)/2)*np.log(Vn) ).sum(0)\n",
    "\n",
    "def fullcov_obs_log_likelihood(data, t, s):\n",
    "    '''Full Covariance model from xuan et al'''\n",
    "    s += 1\n",
    "    n = s - t\n",
    "    x = data[t:s]\n",
    "    if len(x.shape)==2:\n",
    "        dim = x.shape[1]\n",
    "    else:\n",
    "        dim = 1\n",
    "        x = np.atleast_2d(x).T\n",
    "\n",
    "    N0 = dim          # weakest prior we can use to retain proper prior\n",
    "    V0 = np.var(x)*np.eye(dim)\n",
    "    \n",
    "    # Improvement over np.outer\n",
    "    # http://stackoverflow.com/questions/17437523/python-fast-way-to-sum-outer-products\n",
    "    # Vn = V0 + np.array([np.outer(x[i], x[i].T) for i in xrange(x.shape[0])]).sum(0)\n",
    "    Vn = V0 + np.einsum('ij,ik->jk', x, x)\n",
    "\n",
    "    # section 3.2 from Xuan paper:\n",
    "    return -(dim*n/2)*np.log(np.pi) + (N0/2)*np.linalg.slogdet(V0)[1] - \\\n",
    "        multigammaln(N0/2,dim) + multigammaln((N0+n)/2,dim) - \\\n",
    "        ((N0+n)/2)*np.linalg.slogdet(Vn)[1]\n",
    "\n",
    "def const_prior(r, l):\n",
    "    return 1/(l)\n",
    "\n",
    "def geometric_prior(t, p):\n",
    "    return p * ((1 - p) ** (t - 1))\n",
    "\n",
    "def neg_binominal_prior(t, k, p):\n",
    "    return comb(t - k, k - 1) * p ** k * (1 - p) ** (t - k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import binarize\n",
    "from functools import partial\n",
    "\n",
    "data = df.ild.values\n",
    "Q, P, Pcp = offline_changepoint_detection(data, partial(const_prior, l=(len(data)+1)), \n",
    "                                              gaussian_obs_log_likelihood, truncate=-90)\n",
    "picks = np.exp(Pcp).sum(0)\n",
    "picks = picks.reshape(1,-1)\n",
    "bin_picks = np.squeeze(binarize(picks, threshold = 0.3))*45\n",
    "df['sn_top']=np.append(bin_picks, 45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['interval'] = np.nan\n",
    "intervals = df[df['sn_top']>1].depth.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intervals = df[df['sn_top']>1].depth.values\n",
    "for i in range(len(intervals)-1):\n",
    "    ind = df[(df['depth']>intervals[i]) & (df['depth']<intervals[i+1])].index\n",
    "    df.loc[ind, 'interval'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(r'D:/ak_out/5002320004.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.sn_top.plot()\n",
    "df.ild.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
